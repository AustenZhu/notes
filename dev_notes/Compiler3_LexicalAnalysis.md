
# Lexical Analysis

 - We begin the study of lexical-analyzer generators by introducing regular expressions. 
 - We show how this notation can be transformed, 
 	- first into nondeterministic automata and then into deterministic automata. 
 - The latter two notations can be used as input to a "driver", 
 	- that is, code which simulates these automata and uses them as a guide to determining the next token.
 - This driver and the specification of the automaton form the nucleus of the lexical analyzer.

---

## 3.1 The Role of the Lexical Analyzer

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/Compiler_F3.1.png)

lexical analyzer may perform certain other tasks besides identi cation of lexemes.

 - stripping out comments and *whitespace*
 - correlating error messages generated by the compiler with the source program. 

In some compilers, the lexical analyzer makes a copy of the source program with the error messages inserted at the appropriate positions.  If the source program uses a macro-preprocessor, the expansion of macros may also be performed by the lexical analyzer.

Sometimes, lexical analyzers are divided into a cascade of two processes:

 - a) *Scanning* consists of the simple processes that do not require tokenization of the input, 
 	- such as deletion of comments and compaction of consecutive whitespace characters into one.
 - b) *Lexical analysis* proper is the more complex portion, where the scanner produces the sequence of tokens as output.

---

### 3.1.1 Lexical Analysis Versus Parsing










