
# Markov Models

User attention:

let's say you tried to follow where you just pay attention on the screen you attract your attention to your advertising , for example.

---


## Markov Models

Markov model means sequence of random variables. 

X₁ has an influence on X₂ going to be , X₂ has an influcence on X₃ going to be , ... 


 - Parameters: called ***transition probabilities*** or dynamics, specify how the state evolves over time (also, initial state probabilities)
 - Stationarity assumption: transition probabilities the same at all times
    - this means transition probabilities P(x<sub>t</sub> | x<sub>t-1</sub> ) don't depend on time, they are always the same. 
 - Same as MDP transition model, but no choice of action
    
### Joint Distribution of a Markov Model

This case let's look at just 4 variables. 

### Chain Rule and Markov Models

X₃ ⫫ X₁|X₂  

What dose that mean ?  That means that once somebody tells you the value of X₂,  you write the distribution of X₃ ; somebody then tells you what X₁ is and the distribution of X₃ doesn't change -- stays the same. 


### Implied Conditional Independencies 



### Markov Models Recap 

### Example Markov Chain : Weather

### Example Run of Mini-Forward Algorithm

the stationary distribution of Markov Model


